{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from torch import cuda\n",
    "from lib.dataset_utils import *\n",
    "from lib.plot_utils import *\n",
    "from lib.scores import *\n",
    "from lib.models import *\n",
    "from lib.cross_validation import *\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from lib.transformers_explainability import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "DATASET = DatasetEnum.TwitterDataCleaned\n",
    "DATASET_UNCLEANED = DatasetEnum.TwitterData\n",
    "SEED_VAL = 777\n",
    "DATASET_NAME = 'TwitterData'\n",
    "MODEL_NAME = 'SocBert'\n",
    "CHECKPOINT_DIR = './checkpoints/' + DATASET_NAME + '/'\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "CHECKPOINT_MODEL_FILE = CHECKPOINT_DIR + DATASET_NAME + '_' + MODEL_NAME + '.pth'\n",
    "EPOCHS = 6\n",
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "train_df, val_df, test_df = load_dataset(DATASET)\n",
    "LABEL_COLS = train_df.columns[1:].tolist()\n",
    "# scores dictionary\n",
    "SCORES = {'accuracy': sl_accuracy,\n",
    "          'f1_macro': sl_f1_macro,\n",
    "          'f1_micro': sl_f1_micro}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_explore = {\n",
    "    'learning_rate': [5e-05, 1e-05],\n",
    "    'regularization': [0, 1e-05],\n",
    "    'batch_size': [16, 32],\n",
    "    'epochs': [EPOCHS],\n",
    "    'n_classes': [len(LABEL_COLS)],\n",
    "}\n",
    "RESULT_DIR = './results/' + DATASET_NAME + '/'\n",
    "RESULT_FILE = RESULT_DIR + DATASET_NAME + '_' + MODEL_NAME + '.csv'\n",
    "# create the grid search object\n",
    "grid_search = HoldOutCrossValidation(Socbert, SCORES, train_df, val_df, param_dict=params_to_explore, res_file=RESULT_FILE)\n",
    "# run the grid search\n",
    "grid_search.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results\n",
    "results = grid_search.get_results()\n",
    "# get the best parameters and scores according to F1 macro\n",
    "best_info = grid_search.get_best_info('f1_macro')\n",
    "print(\"BEST MODEL INFO\")\n",
    "print(best_info)\n",
    "# print the results\n",
    "print(\"RESULTS\")\n",
    "print(results)\n",
    "print(\"BEST PARAMS\")\n",
    "BEST_PARAMS = grid_search.get_best_params('f1_macro')\n",
    "BEST_PARAMS['batch_size'] = int(BEST_PARAMS['batch_size'])\n",
    "BEST_PARAMS['epochs'] = int(BEST_PARAMS['epochs'])\n",
    "BEST_PARAMS['n_classes'] = int(BEST_PARAMS['n_classes'])\n",
    "print(BEST_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED_VAL)\n",
    "torch.manual_seed(SEED_VAL)\n",
    "np.random.seed(SEED_VAL)\n",
    "torch.cuda.manual_seed_all(SEED_VAL)\n",
    "# create the model with the best parameters\n",
    "model = Socbert(SCORES, BEST_PARAMS, CHECKPOINT_MODEL_FILE)\n",
    "# fit the model if checkpoint does not exist\n",
    "if not os.path.exists(CHECKPOINT_MODEL_FILE):\n",
    "    model.fit(train_df, validation_df=val_df, progress_bar_epoch=True, progress_bar_step=False, checkpoint_path=CHECKPOINT_MODEL_FILE, checkpoint_score='f1_macro', checkpoint_score_maximize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_model_analysis(model, val_df, LABEL_COLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt with no cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_MODEL_FILE = CHECKPOINT_DIR + DATASET_NAME + '_' + MODEL_NAME + '_uncleaned.pth'\n",
    "train_df, val_df, test_df = load_dataset(DATASET_UNCLEANED, k_hot_encode=True)\n",
    "random.seed(SEED_VAL)\n",
    "torch.manual_seed(SEED_VAL)\n",
    "np.random.seed(SEED_VAL)\n",
    "torch.cuda.manual_seed_all(SEED_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Socbert({'f1_macro':f1}, BEST_PARAMS, CHECKPOINT_MODEL_FILE)\n",
    "if not os.path.exists(CHECKPOINT_MODEL_FILE):\n",
    "    model.fit(train_df, validation_df=val_df, progress_bar_epoch=True, progress_bar_step=False, checkpoint_path=CHECKPOINT_MODEL_FILE, checkpoint_score='f1_macro', checkpoint_score_maximize=True, shuffle_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_model_analysis(model, val_df, LABEL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_uncleaned = model.predict(val_df)\n",
    "target = val_df[LABEL_COLS].values\n",
    "out_uncleaned = np.argmax(out_uncleaned, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_MODEL_FILE = CHECKPOINT_DIR + DATASET_NAME + '_' + MODEL_NAME + '_cleaned_seq.pth'\n",
    "train_df, val_df, test_df = load_dataset(DATASET)\n",
    "random.seed(SEED_VAL)\n",
    "torch.manual_seed(SEED_VAL)\n",
    "np.random.seed(SEED_VAL)\n",
    "torch.cuda.manual_seed_all(SEED_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Socbert({'f1_macro':f1}, BEST_PARAMS, CHECKPOINT_MODEL_FILE)\n",
    "if not os.path.exists(CHECKPOINT_MODEL_FILE):\n",
    "    model.fit(train_df, validation_df=val_df, progress_bar_epoch=True, progress_bar_step=False, checkpoint_path=CHECKPOINT_MODEL_FILE, checkpoint_score='f1_macro', checkpoint_score_maximize=True, shuffle_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cleaned = model.predict(val_df)\n",
    "out_cleaned = np.argmax(out_cleaned, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_score = f1_score(target, out_cleaned,average=None)\n",
    "uncleaned_score = f1_score(target, out_uncleaned,average=None)\n",
    "\n",
    "# we create a dataframe with for each label the f1 score for both the models\n",
    "results_df=pd.DataFrame(zip(LABEL_COLS,cleaned_score,uncleaned_score),columns=[\"labels\",\"CLEANED SCORE\",\"UNCLEANED SCORE\"])\n",
    "results_df = pd.melt(results_df, id_vars=\"labels\", var_name=\"models\", value_name=\"f1_score\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "barplot=sns.barplot(x=\"labels\", hue=\"models\", y=\"f1_score\", data=results_df)\n",
    "barplot.set_xticklabels(barplot.get_xticklabels(), \n",
    "                          rotation=90, \n",
    "                          horizontalalignment='right')\n",
    "plt.show()\n",
    "\n",
    "print(f\"cleaned mean = {np.mean(cleaned_score)}\\nuncleaned mean = {np.mean(uncleaned_score)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HLT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
